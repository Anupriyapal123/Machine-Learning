# -*- coding: utf-8 -*-
"""NLP_ngram.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dZbupowP0yEeeJFCkgR3HtX7UEcQ3Mk6
"""

import os
import json
import gzip
import pandas as pd
from urllib.request import urlopen
import sklearn
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
import string
import re
from bs4 import BeautifulSoup
!pip install contractions
import contractions
from collections import Counter

#readin the data from file and generate dataframe
def parse(path):
  g = gzip.open('reviews_Amazon_Instant_Video_5.json.gz', 'rb')
  for l in g:
    yield eval(l)

def getDF(path):
  i = 0
  df = {}
  for d in parse(path):
    df[i] = d
    i += 1
  return pd.DataFrame.from_dict(df, orient='index')

df = getDF('reviews_Video_Games.json.gz')
print(df['reviewText'][0:10])

reviewText = np.array(df.reviewText)
print(reviewText[0:10])
ratings = np.array(df.overall)
print(ratings[0:10])

#converting rating to good('1') and bad('0')
for i in range(len(ratings)):
  if ratings[i]>3:
    ratings[i] = 1
  else:
    ratings[i] = 0  
print(ratings[0:10])

def preprocess_string(s):
  # Remove all non-word characters (everything except numbers and letters)
  s = re.sub(r"[^\w\s]", '', s)
  # Replace all runs of whitespaces with no space
  s = re.sub(r"\s+", '', s)
  # replace digits with no space
  s = re.sub(r"\d", '', s)
  return s

def replace_contactions(text):
  return contractions.fix(text)

#building the vocabulary
word_list = []
for sentence in reviewText:
  sentence = replace_contactions(sentence)
  for word in sentence.lower().split():
    word = preprocess_string(word)
    # print(word)
    word_list.append(word)
corpus = Counter(word_list)
print(len(corpus))

print(corpus)

from nltk.util import ngrams
n = 2
n_grams = ngrams(word_list, n)
n_corpus = Counter(n_grams)
print(n_corpus.most_common()[0:100])

n = 3
n_grams = ngrams(word_list, n)
n_corpus = Counter(n_grams)
print(n_corpus.most_common()[0:100])

frequency = np.array(sorted(corpus.values(),reverse=True))
x_axis = np.array(range(1,len(frequency)+1))
print("frequency: ",frequency)
print("rank: ",x_axis)
frequency = np.log(frequency)
print("frequency in log: ",frequency)
x_axis = np.log(x_axis)
print("rank in log: ",x_axis)

import matplotlib.pyplot as plt
#plt.figure(figsize=(16, 9))
plt.figure()
plt.plot(x_axis,frequency)
plt.show()

from sklearn.linear_model import LinearRegression
reg = LinearRegression().fit(x_axis.reshape(-1,1), frequency.reshape(-1,1))
pred_list = []
y_axis = reg.predict(x_axis.reshape(-1,1))
print(y_axis)
#plt.figure(figsize=(16, 9))
plt.figure()
plt.plot(x_axis,frequency)
plt.plot(x_axis,y_axis)
plt.show()

import nltk
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
lower_case = reviewText[1].lower()
tokens = nltk.word_tokenize(lower_case)
print(lower_case)
print(nltk.pos_tag(tokens))